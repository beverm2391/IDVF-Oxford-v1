{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = []\n",
    "date = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, train_index, predict_index,  lr,  names, Epoch_num = 300, pre = True):\n",
    "\n",
    "        temp_train_start = np.where(self.a.idx == train_index[0])\n",
    "        temp_index_train = []\n",
    "        for i in temp_train_start[0]:\n",
    "            temp_index_train.extend(list(range(i, i + len(train_index))))\n",
    "        temp_predict_start = np.where(self.a.idx == predict_index[0])\n",
    "        temp_index_predict = []\n",
    "        for i in temp_predict_start[0]:\n",
    "            temp_index_predict.extend(list(range(i, i + len(predict_index))))\n",
    "        train_x = self.a.x[temp_index_train]\n",
    "        train_y = self.a.y[temp_index_train]\n",
    "        test_x = self.a.x[temp_index_predict]\n",
    "        test_y = self.a.y[temp_index_predict]\n",
    "\n",
    "        train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "        test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "        train_x = np.concatenate((np.ones((train_x.shape[0], 1)), train_x), axis=1)\n",
    "        test_x = np.concatenate((np.ones((test_x.shape[0], 1)), test_x), axis=1)\n",
    "\n",
    "        beta = np.matmul(np.matmul(np.linalg.inv(np.matmul(train_x.T, train_x)), train_x.T), train_y)\n",
    "        predict = np.matmul(test_x, beta)\n",
    "\n",
    "        predict = np.reshape(predict, (-1, len(namelist)), 'F')\n",
    "        test_y = np.reshape(test_y, (-1, len(namelist)), 'F')\n",
    "        plot_valid = np.concatenate((predict, test_y), axis=1)\n",
    "        plot_valid = pd.DataFrame(plot_valid)\n",
    "        plot_valid.index = date[(np.where(date == predict_index[0])[0][0] + 1):(\n",
    "                np.where(date == predict_index[-1])[0][0] + 2)]\n",
    "        plot_valid.columns = [x + 'out' for x in namelist] + [x + 'real' for x in namelist]\n",
    "        return plot_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(self, train_index, predict_index,  lr,  names, Epoch_num = 300, pre = True):\n",
    "\n",
    "        clf = linear_model.Lasso(alpha=1e-4,tol=1e-3) # ! new model\n",
    "\n",
    "        temp_train_start = np.where(self.a.idx == train_index[0])\n",
    "        temp_index_train = []\n",
    "        for i in temp_train_start[0]:\n",
    "            temp_index_train.extend(list(range(i,i+len(train_index))))\n",
    "        temp_predict_start = np.where(self.a.idx == predict_index[0])\n",
    "        temp_index_predict= []\n",
    "        for i in temp_predict_start[0]:\n",
    "            temp_index_predict.extend(list(range(i,i+len(predict_index))))\n",
    "        train_x = self.a.x[temp_index_train]\n",
    "        train_y = self.a.y[temp_index_train]\n",
    "        test_x = self.a.x[temp_index_predict]\n",
    "        test_y = self.a.y[temp_index_predict]\n",
    "\n",
    "        # ! new stuff\n",
    "        train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "        test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "\n",
    "        clf.fit(train_x,train_y)\n",
    "\n",
    "        predict = clf.predict(test_x)\n",
    "\n",
    "        # plot_valid_exp = np.exp(plot_valid[['out','real']])\n",
    "        # print(np.mean((plot_valid_exp.iloc[:,0]-plot_valid_exp.iloc[:,1])**2))\n",
    "        # plt.plot(train_list)\n",
    "        # plt.plot(valid_list)\n",
    "        predict = np.reshape(predict, (-1, len(namelist)), 'F')\n",
    "        test_y = np.reshape(test_y, (-1, len(namelist)), 'F')\n",
    "        plot_valid = np.concatenate((predict, test_y), axis=1)\n",
    "        plot_valid = pd.DataFrame(plot_valid)\n",
    "        plot_valid.index = date[(np.where(date == predict_index[0])[0][0] + 1):(\n",
    "                    np.where(date == predict_index[-1])[0][0] + 2)]\n",
    "        plot_valid.columns = [x + 'out' for x in namelist] + [x + 'real' for x in namelist]\n",
    "        return plot_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, train_index, predict_index,  lr,  names, Epoch_num = 300, pre = True):\n",
    "        temp_train_start = np.where(self.a.idx == train_index[0])\n",
    "        temp_index_train = []\n",
    "        for i in temp_train_start[0]:\n",
    "            temp_index_train.extend(list(range(i, i + len(train_index))))\n",
    "        temp_predict_start = np.where(self.a.idx == predict_index[0])\n",
    "        temp_index_predict = []\n",
    "        for i in temp_predict_start[0]:\n",
    "            temp_index_predict.extend(list(range(i, i + len(predict_index))))\n",
    "        train_x = self.a.x[temp_index_train]\n",
    "        train_y = self.a.y[temp_index_train]\n",
    "        test_x = self.a.x[temp_index_predict]\n",
    "        test_y = self.a.y[temp_index_predict]\n",
    "\n",
    "        train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "        test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "        train_x = np.concatenate((np.ones((train_x.shape[0], 1)), train_x), axis=1)\n",
    "        test_x = np.concatenate((np.ones((test_x.shape[0], 1)), test_x), axis=1)\n",
    "\n",
    "        beta = np.matmul(np.matmul(np.linalg.inv(np.matmul(train_x.T, train_x)), train_x.T), train_y)\n",
    "        predict = np.matmul(test_x, beta)\n",
    "\n",
    "        predict = np.reshape(predict, (-1, len(namelist)), 'F')\n",
    "        test_y = np.reshape(test_y, (-1, len(namelist)), 'F')\n",
    "        plot_valid = np.concatenate((predict, test_y), axis=1)\n",
    "        plot_valid = pd.DataFrame(plot_valid)\n",
    "        plot_valid.index = date[(np.where(date == predict_index[0])[0][0] + 1):(\n",
    "                np.where(date == predict_index[-1])[0][0] + 2)]\n",
    "        plot_valid.columns = [x + 'out' for x in namelist] + [x + 'real' for x in namelist]\n",
    "        return plot_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, train_index, predict_index,  lr,  names, Epoch_num = 300, pre = True):\n",
    "        print(f\"Training on {train_index[0]} - {train_index[-1]}\")\n",
    "        print(f\"Predicting on {predict_index[0]} - {predict_index[-1]}\")\n",
    "\n",
    "        val_set_size = 100\n",
    "        assert val_set_size < window_length / count_one_day,\\\n",
    "            f\"val_set_size {val_set_size} must be less than {window_length / count_one_day} (window_length / count_one_day)\"\n",
    "\n",
    "        temp_train_start = np.where(self.a.idx == train_index[0])\n",
    "        assert temp_train_start != [], f\"train_index[0] {train_index[0]} not in index {self.a.idx}\"\n",
    "\n",
    "        # training set\n",
    "        temp_index_train = []\n",
    "        for i in temp_train_start[0]:\n",
    "            temp_index_train.extend(list(range(i, i + len(train_index) - val_set_size * count_one_day))) #! offset by val_set_size days - i think this is to create the validation set\n",
    "\n",
    "        # validation set\n",
    "        temp_index_valid = []\n",
    "        for i in temp_train_start[0]:\n",
    "            temp_index_valid.extend(list(range(i + len(train_index) - val_set_size * count_one_day, i + len(train_index))))\n",
    "\n",
    "        # testing set\n",
    "        temp_predict_start = np.where(self.a.idx == predict_index[0])\n",
    "        temp_index_predict = []\n",
    "        for i in temp_predict_start[0]:\n",
    "            temp_index_predict.extend(list(range(i, i + len(predict_index))))\n",
    "\n",
    "        # make datasets\n",
    "        train_x = self.a.x[temp_index_train]\n",
    "        train_y = self.a.y[temp_index_train]\n",
    "        valid_x = self.a.x[temp_index_valid]\n",
    "        valid_y = self.a.y[temp_index_valid]\n",
    "        test_x = self.a.x[temp_index_predict]\n",
    "        test_y = self.a.y[temp_index_predict]\n",
    "\n",
    "        x_stats = mean_var(train_x) #! normalize\n",
    "        y_stats = mean_var(train_y) #! normalize\n",
    "\n",
    "        train_x = x_stats.preprocess(train_x)\n",
    "        train_y = y_stats.preprocess(train_y)\n",
    "\n",
    "        valid_x = x_stats.preprocess(valid_x)\n",
    "        valid_y = y_stats.preprocess(valid_y)\n",
    "\n",
    "        test_x  = x_stats.preprocess(test_x)\n",
    "        #test_y  = y_stats.preprocess(test_y)\n",
    "\n",
    "        train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "        test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "        valid_x = valid_x.reshape(valid_x.shape[0], -1)\n",
    "\n",
    "        from lib.earlystopping import EarlyStopping #! early stopping\n",
    "\n",
    "        if lr is None: lr = self.lr # if lr not passed to train, use default lr for RP class\n",
    "        if names is None: names = self.keywords # if names not passed to train, use default names for RP class\n",
    "\n",
    "        trainloader = DataLoader(TensorDataset(torch.tensor(train_x), torch.tensor(train_y)),1024,\n",
    "                                 shuffle=True) #! batch size 1024, shuffle=True, TensorDataset loafs all data into memory\n",
    "        validloader1 = DataLoader(TensorDataset(torch.tensor(valid_x), torch.tensor(valid_y)),\n",
    "                                  torch.tensor(valid_x).shape[0],\n",
    "                                  shuffle=False) #! batch size = valid_x.shape[0] (num in val set, 250), shuffle=False\n",
    "        validloader2 = DataLoader( TensorDataset(torch.tensor(test_x), torch.tensor(test_y)),\n",
    "            len(torch.tensor(test_y)), shuffle=False) #! batch size = len(test_y), shuffle=False\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=10, verbose=False, path=f\"{models_dir}temp/checkpoint.pt\") # early stopping\n",
    "        net = DNN(train_x.shape[1], 1).to(device) # init the dnn, move it to gpu if available\n",
    "        loss_function = nn.MSELoss() # loss function\n",
    "        optimiser = optim.Adam(net.parameters(), lr=lr, eps=1e-8) # optimizer\n",
    "        Epoch_num = Epoch_num # not sure why this is here\n",
    "\n",
    "        for epoch in range(Epoch_num + 1):\n",
    "            net.train() # set model to train mode\n",
    "            for data_val, target in trainloader: # iterate over batches\n",
    "                optimiser.zero_grad() # zero gradients\n",
    "                output = net(data_val.float().to(device)) # forward pass\n",
    "                loss = loss_function(output.float().view(-1), target.float().view(-1).to(device)) # compute loss\n",
    "                loss.backward() # backprop\n",
    "                optimiser.step() # update weights\n",
    "            net.eval() # set model to eval mode\n",
    "            for data_val, target in validloader1: \n",
    "                output = net(data_val.float().to(device)) # forward pass\n",
    "                loss_valid = loss_function(output.float().view(-1), target.float().view(-1).to(device)) # compute loss\n",
    "\n",
    "            # valid_list.append(loss_valid.float().view(-1).detach().cpu().numpy()[0])\n",
    "            # test_list.append(loss_test.float().view(-1).detach().cpu().numpy()[0])\n",
    "            early_stopping(loss_valid.detach().cpu().numpy().reshape(-1)[0], net) # early stopping\n",
    "            # if output.max() - output.min() < 0.2 and target.max() - target.min() > 1:\n",
    "            #      early_stopping = EarlyStopping(patience=2000, verbose=False, path=model_name)\n",
    "\n",
    "            tl = loss_valid.float().view(-1).detach().cpu().numpy()[0]\n",
    "            vl = loss_valid.float().view(-1).detach().cpu().numpy()[0]\n",
    "\n",
    "            print(f\"Epoch: {epoch} of {Epoch_num} | Train Loss: {tl:0.4f} | Valid Loss: {vl:0.4f}\")\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "\n",
    "        net.load_state_dict(torch.load(f\"{models_dir}temp/checkpoint.pt\")) # load best model\n",
    "        # print(epoch)\n",
    "        model_name = f'Best_Model_{str(predict_index[0])}-{str(predict_index[-1])}.pt'\n",
    "        torch.save(net.state_dict(), os.path.join(models_dir, model_name)) # save best model\n",
    "\n",
    "        net.eval() # set model to eval mode\n",
    "        for data_val, target in validloader2:\n",
    "\n",
    "            output = net(data_val.float().to(device)) # forward pass\n",
    "\n",
    "        predict = output.float().view(-1).detach().cpu().numpy() # get predictions\n",
    "        predict = y_stats.back(predict) # denormalize predictions\n",
    "\n",
    "        predict = np.reshape(predict, (-1, len(namelist)), 'F') # reshape predictions, fortran order\n",
    "        test_y = np.reshape(test_y, (-1, len(namelist)), 'F') # reshape test_y, fortran order\n",
    "        plot_valid = np.concatenate((predict, test_y), axis=1) \n",
    "        plot_valid = pd.DataFrame(plot_valid)\n",
    "        plot_valid.index = date[(np.where(date == predict_index[0])[0][0] + 1):(\n",
    "                np.where(date == predict_index[-1])[0][0] + 2)]\n",
    "        plot_valid.columns = [x + 'out' for x in namelist] + [x + 'real' for x in namelist]\n",
    "        return plot_valid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
