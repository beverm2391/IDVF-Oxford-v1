{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_preprocess(data, windsorize=True):\n",
    "    data = data.ffill()\n",
    "    data = data.bfill()\n",
    "    assert data.isna().sum().sum() == 0\n",
    "\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], utc=True).dt.tz_convert('US/Eastern')\n",
    "    data.set_index('datetime', inplace=True)\n",
    "\n",
    "    data.columns = [col for col in data.columns if col != 'datetime'] # filter out datetime\n",
    "    date = data.index\n",
    "\n",
    "    namelist = data.columns.tolist()\n",
    "\n",
    "    if windsorize:\n",
    "        for clm in data.columns:\n",
    "            max_p = np.percentile(data[clm], 99.9)\n",
    "            min_p = np.percentile(data[clm], 0.1)\n",
    "\n",
    "            data.loc[data[clm] > max_p, clm] = max_p\n",
    "            data.loc[data[clm] < min_p, clm] = min_p\n",
    "\n",
    "    return data, date, namelist\n",
    "\n",
    "rv_data = pd.read_csv('/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/data/processed-5yr-93-minute/65min_rv.csv', index_col=0)\n",
    "\n",
    "back_day = 6*20\n",
    "back_day = list(range(back_day))\n",
    "window_length = 6*250\n",
    "train_size = 1000 #! MODIFIED for smaller dataset\n",
    "count_one_day = 6\n",
    "\n",
    "data, date, namelist = initial_preprocess(rv_data, windsorize=False) # preprocess data, no windsorization\n",
    "\n",
    "data.columns = [col + '_logvol' for col in data.columns] # rename columns\n",
    "\n",
    "models_dir = '/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/models/'\n",
    "model_name = f'checkpoint.pt'\n",
    "temp_path = f\"{models_dir}/temp/\"\n",
    "save_path = '/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/models/'+ model_name\n",
    "\n",
    "if not os.path.exists(temp_path): os.makedirs(temp_path) # create models and temp folders if they don't exist\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(DNN, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(input_size, 128),\n",
    "            *block(128, 32),\n",
    "            nn.Linear(32, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        forecast_y = self.model(x)\n",
    "        return forecast_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess():\n",
    "    def __init__(self, input, target, back_day = list(range(0,15)), forward_day = 1):\n",
    "        #input is a list of dataframes, for example [price,volatility] with index as the same as target.\n",
    "        self.x = []\n",
    "        for _ in input:\n",
    "            self.x.append(np.expand_dims(np.array(pd.concat(list(map(lambda n: _.shift(n), back_day)), axis=1).reset_index(drop=True).loc[:,::-1]),axis =2))\n",
    "        self.x = np.concatenate(tuple(self.x),axis =2)\n",
    "        self.idx1 = [~np.any(np.isnan(p)) for p in self.x]\n",
    "        self.y = target.shift(-forward_day)\n",
    "        self.y = pd.DataFrame((self.y)).reset_index(drop=True)\n",
    "        self.idx2 = self.y.notna().all(axis = 1)\n",
    "        self.idx = np.logical_and(self.idx1, self.idx2)\n",
    "        self.x = self.x[self.idx]\n",
    "        self.y = np.array(self.y[self.idx].reset_index(drop = True))\n",
    "\n",
    "        self.idx = data.index[self.idx]\n",
    "\n",
    "\n",
    "class mean_var():\n",
    "    def __init__(self, data):\n",
    "        self.ave = np.mean(data, axis = 0)\n",
    "        self.var = np.var(data,axis = 0)\n",
    "    def preprocess(self, temp):\n",
    "        return (temp - self.ave)/np.sqrt(self.var)\n",
    "    def back(self, temp):\n",
    "        return temp * np.sqrt(self.var)+self.ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rolling_predict():\n",
    "    def __init__(self, keywords = ['XVZ_volatility'], back_day = list(range(0,15)), lr = 0.001):\n",
    "        self.back_day = back_day\n",
    "        self.lr = lr\n",
    "        self.keywords = keywords\n",
    "        temp = [data[namelist[0] + '_logvol']]\n",
    "        print(\"Preprocessing data...\")\n",
    "        self.a = preprocess(temp, data[namelist[0] + '_logvol'], back_day=back_day)\n",
    "\n",
    "        for ind in namelist[1:]:\n",
    "            temp = []\n",
    "            for i in [ind + '_logvol']:\n",
    "                temp.append(data[i])\n",
    "            temp_a = preprocess(temp, data[ind + '_logvol'], back_day=back_day)\n",
    "            self.a.x = np.concatenate([self.a.x, temp_a.x], axis=0)\n",
    "            self.a.y = np.concatenate([self.a.y, temp_a.y], axis=0)\n",
    "            self.a.idx = np.concatenate([self.a.idx, temp_a.idx], axis=0)\n",
    "\n",
    "    def train(self, train_index, predict_index,  lr,  names, Epoch_num = 300, pre = True):\n",
    "        print(f\"Training on {train_index[0]} - {train_index[-1]}\")\n",
    "        print(f\"Predicting on {predict_index[0]} - {predict_index[-1]}\")\n",
    "\n",
    "        val_set_size = 100\n",
    "        assert val_set_size < window_length / count_one_day,\\\n",
    "            f\"val_set_size {val_set_size} must be less than {window_length / count_one_day} (window_length / count_one_day)\"\n",
    "\n",
    "        temp_train_start = np.where(self.a.idx == train_index[0])\n",
    "        assert temp_train_start != [], f\"train_index[0] {train_index[0]} not in index {self.a.idx}\"\n",
    "\n",
    "        # training set\n",
    "        temp_index_train = []\n",
    "        for i in temp_train_start[0]:\n",
    "            temp_index_train.extend(list(range(i, i + len(train_index) - val_set_size * count_one_day))) #! offset by val_set_size days - i think this is to create the validation set\n",
    "\n",
    "        # validation set\n",
    "        temp_index_valid = []\n",
    "        for i in temp_train_start[0]:\n",
    "            temp_index_valid.extend(list(range(i + len(train_index) - val_set_size * count_one_day, i + len(train_index))))\n",
    "\n",
    "        # testing set\n",
    "        temp_predict_start = np.where(self.a.idx == predict_index[0])\n",
    "        temp_index_predict = []\n",
    "        for i in temp_predict_start[0]:\n",
    "            temp_index_predict.extend(list(range(i, i + len(predict_index))))\n",
    "\n",
    "        # make datasets\n",
    "        train_x = self.a.x[temp_index_train]\n",
    "        train_y = self.a.y[temp_index_train]\n",
    "        valid_x = self.a.x[temp_index_valid]\n",
    "        valid_y = self.a.y[temp_index_valid]\n",
    "        test_x = self.a.x[temp_index_predict]\n",
    "        test_y = self.a.y[temp_index_predict]\n",
    "\n",
    "        x_stats = mean_var(train_x) #! normalize\n",
    "        y_stats = mean_var(train_y) #! normalize\n",
    "\n",
    "        train_x = x_stats.preprocess(train_x)\n",
    "        train_y = y_stats.preprocess(train_y)\n",
    "\n",
    "        valid_x = x_stats.preprocess(valid_x)\n",
    "        valid_y = y_stats.preprocess(valid_y)\n",
    "\n",
    "        test_x  = x_stats.preprocess(test_x)\n",
    "        #test_y  = y_stats.preprocess(test_y)\n",
    "\n",
    "        train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "        test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "        valid_x = valid_x.reshape(valid_x.shape[0], -1)\n",
    "\n",
    "        from lib.earlystopping import EarlyStopping #! early stopping\n",
    "\n",
    "        if lr is None: lr = self.lr # if lr not passed to train, use default lr for RP class\n",
    "        if names is None: names = self.keywords # if names not passed to train, use default names for RP class\n",
    "\n",
    "        trainloader = DataLoader(TensorDataset(torch.tensor(train_x), torch.tensor(train_y)),1024,\n",
    "                                 shuffle=True) #! batch size 1024, shuffle=True, TensorDataset loafs all data into memory\n",
    "        validloader1 = DataLoader(TensorDataset(torch.tensor(valid_x), torch.tensor(valid_y)),\n",
    "                                  torch.tensor(valid_x).shape[0],\n",
    "                                  shuffle=False) #! batch size = valid_x.shape[0] (num in val set, 250), shuffle=False\n",
    "        validloader2 = DataLoader( TensorDataset(torch.tensor(test_x), torch.tensor(test_y)),\n",
    "            len(torch.tensor(test_y)), shuffle=False) #! batch size = len(test_y), shuffle=False\n",
    "\n",
    "        early_stopping = EarlyStopping(patience=10, verbose=False, path=f\"{temp_path}{model_name}\") # early stopping\n",
    "        net = DNN(train_x.shape[1], 1).to(device) # init the dnn, move it to gpu if available\n",
    "        loss_function = nn.MSELoss() # loss function\n",
    "        optimiser = optim.Adam(net.parameters(), lr=lr, eps=1e-8) # optimizer\n",
    "        Epoch_num = Epoch_num # not sure why this is here\n",
    "\n",
    "        for epoch in range(Epoch_num):\n",
    "            net.train() # set model to train mode\n",
    "            for data_val, target in trainloader: # iterate over batches\n",
    "                optimiser.zero_grad() # zero gradients\n",
    "                output = net(data_val.float().to(device)) # forward pass\n",
    "                loss = loss_function(output.float().view(-1), target.float().view(-1).to(device)) # compute loss\n",
    "                loss.backward() # backprop\n",
    "                optimiser.step() # update weights\n",
    "            net.eval() # set model to eval mode\n",
    "            for data_val, target in validloader1: \n",
    "                output = net(data_val.float().to(device)) # forward pass\n",
    "                loss_valid = loss_function(output.float().view(-1), target.float().view(-1).to(device)) # compute loss\n",
    "\n",
    "            # valid_list.append(loss_valid.float().view(-1).detach().cpu().numpy()[0])\n",
    "            # test_list.append(loss_test.float().view(-1).detach().cpu().numpy()[0])\n",
    "            early_stopping(loss_valid.detach().cpu().numpy().reshape(-1)[0], net) # early stopping\n",
    "            # if output.max() - output.min() < 0.2 and target.max() - target.min() > 1:\n",
    "            #      early_stopping = EarlyStopping(patience=2000, verbose=False, path=model_name)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                break\n",
    "\n",
    "        net.load_state_dict(torch.load(temp_path + model_name)) # load best model\n",
    "        print(epoch) # print epoch\n",
    "        torch.save(net.state_dict(), os.path.join(save_path, 'Best_Model' +'_' + str(predict_index[0]-predict_index[-1]))) # save best model\n",
    "\n",
    "        net.eval() # set model to eval mode\n",
    "        for data_val, target in validloader2:\n",
    "\n",
    "            output = net(data_val.float().to(device)) # forward pass\n",
    "\n",
    "        predict = output.float().view(-1).detach().cpu().numpy() # get predictions\n",
    "        predict = y_stats.back(predict) # denormalize predictions\n",
    "\n",
    "        predict = np.reshape(predict, (-1, len(namelist)), 'F') # reshape predictions, fortran order\n",
    "        test_y = np.reshape(test_y, (-1, len(namelist)), 'F') # reshape test_y, fortran order\n",
    "        plot_valid = np.concatenate((predict, test_y), axis=1) \n",
    "        plot_valid = pd.DataFrame(plot_valid)\n",
    "        plot_valid.index = date[(np.where(date == predict_index[0])[0][0] + 1):(\n",
    "                np.where(date == predict_index[-1])[0][0] + 2)]\n",
    "        plot_valid.columns = [x + 'out' for x in namelist] + [x + 'real' for x in namelist]\n",
    "        return plot_valid\n",
    "    \n",
    "    def run(self, window_length, train_size, Epoch_num = 2, pre = True):\n",
    "        T = int(self.a.x.shape[0]/len(namelist))\n",
    "        result_list = []\n",
    "\n",
    "        # ! MODIFIED CODE =========================================================\n",
    "        test_start_date = '2020-06-30' # this is the last date of train, so test will start on the next day\n",
    "        test_start_date = pd.Timestamp(f'{test_start_date} 10:35', tz='US/Eastern') #! this dataset uses intervals form 10:35-16:00 so this should be 10:35 not 9:30\n",
    "        assert test_start_date in self.a.idx, f\"test_start_date {test_start_date} not in index\"\n",
    "        start_index = np.where(self.a.idx == test_start_date)[0][0]\n",
    "        # ! END MODIFIED CODE =====================================================\n",
    "\n",
    "        for start in range(start_index,T-1, window_length):\n",
    "            print(self.a.idx[start])\n",
    "            if start + window_length <= T - 1:\n",
    "                result_list.append(\n",
    "                    self.train(Epoch_num=Epoch_num, train_index=self.a.idx[start_index - train_size:start],\n",
    "                                predict_index=self.a.idx[start:start + window_length], lr=None, names=None, pre=pre))\n",
    "            else:\n",
    "                result_list.append(\n",
    "                    self.train(Epoch_num=Epoch_num, train_index=self.a.idx[start_index - train_size:start],\n",
    "                                predict_index=self.a.idx[start: T - 1], lr=None, names=None, pre=pre))\n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "2020-06-30 10:35:00-04:00\n",
      "Training on 2019-10-29 14:55:00-04:00 - 2020-06-29 16:00:00-04:00\n",
      "1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Timestamp' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m q \u001b[39m=\u001b[39m rolling_predict( back_day\u001b[39m=\u001b[39m back_day,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m             lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m result \u001b[39m=\u001b[39m q\u001b[39m.\u001b[39;49mrun(window_length, train_size, Epoch_num \u001b[39m=\u001b[39;49m \u001b[39m2\u001b[39;49m,pre \u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# ! END UNMODIFIED CODE =========================================================\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# ! REPORTING AND SAVING (modified) ================================================\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_report\u001b[39m(result: pd\u001b[39m.\u001b[39mDataFrame):\n",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=142'>143</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma\u001b[39m.\u001b[39midx[start])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=143'>144</a>\u001b[0m \u001b[39mif\u001b[39;00m start \u001b[39m+\u001b[39m window_length \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m T \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=144'>145</a>\u001b[0m     result_list\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=145'>146</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain(Epoch_num\u001b[39m=\u001b[39;49mEpoch_num, train_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ma\u001b[39m.\u001b[39;49midx[start_index \u001b[39m-\u001b[39;49m train_size:start],\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=146'>147</a>\u001b[0m                     predict_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ma\u001b[39m.\u001b[39;49midx[start:start \u001b[39m+\u001b[39;49m window_length], lr\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, names\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, pre\u001b[39m=\u001b[39;49mpre))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=147'>148</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=148'>149</a>\u001b[0m     result_list\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=149'>150</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain(Epoch_num\u001b[39m=\u001b[39mEpoch_num, train_index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma\u001b[39m.\u001b[39midx[start_index \u001b[39m-\u001b[39m train_size:start],\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m                     predict_index\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39ma\u001b[39m.\u001b[39midx[start: T \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m], lr\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, names\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pre\u001b[39m=\u001b[39mpre))\n",
      "\u001b[1;32m/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m net\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(temp_path \u001b[39m+\u001b[39m model_name)) \u001b[39m# load best model\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m \u001b[39mprint\u001b[39m(epoch) \u001b[39m# print epoch\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m torch\u001b[39m.\u001b[39msave(net\u001b[39m.\u001b[39mstate_dict(), os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_path, \u001b[39m'\u001b[39m\u001b[39mBest_Model\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(predict_index[\u001b[39m0\u001b[39;49m][:\u001b[39m10\u001b[39;49m]))) \u001b[39m# save best model\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m net\u001b[39m.\u001b[39meval() \u001b[39m# set model to eval mode\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/notebooks/dnn-replication-v1.ipynb#W5sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m \u001b[39mfor\u001b[39;00m data_val, target \u001b[39min\u001b[39;00m validloader2:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Timestamp' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "q = rolling_predict( back_day= back_day,\n",
    "            lr=0.001)\n",
    "result = q.run(window_length, train_size, Epoch_num = 2,pre = False)\n",
    "# ! END UNMODIFIED CODE =========================================================\n",
    "\n",
    "# ! REPORTING AND SAVING (modified) ================================================\n",
    "def _make_report(result: pd.DataFrame):\n",
    "        report_df = pd.DataFrame(index = namelist,columns=['MSE','r2_score']) # init report df with MSE and r square\n",
    "        \n",
    "        test_start_date = '2020-06-30' # this is the last date of train, so test will start on the next day\n",
    "        test_start_date = pd.Timestamp(f'{test_start_date} 10:35', tz='US/Eastern') #! this dataset uses intervals form 10:35-16:00 so this should be 10:35 not 9:30\n",
    "        # start the result df freom the test start date\n",
    "        result = result.loc[test_start_date:]\n",
    "\n",
    "        for i in namelist:\n",
    "            # report_df.loc[i,'MSE'] = mean_squared_error(result[i+'out'],result[i+'real']) # calculate MSE\n",
    "            # ! this original code is technically backwards but its sqared so it doesn't matter\n",
    "            report_df.loc[i,'MSE'] = mean_squared_error( result[i + 'real'],result[i + 'out']) # calculate MSE\n",
    "            report_df.loc[i,'r2_score'] = r2_score( result[i + 'real'],result[i + 'out']) # calculate r square\n",
    "            report_df.loc[i,'MAPE'] = mean_absolute_percentage_error( result[i + 'real'],result[i + 'out']) # calculate MAPE\n",
    "        return report_df\n",
    "    \n",
    "def _save(result: pd.DataFrame, report_df: pd.DataFrame, args_dict: Dict = None):\n",
    "    SAVE_DIR = \"/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/outputs/lasso-replication-v1/\"\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)\n",
    "    subdir = f\"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    os.makedirs(os.path.join(SAVE_DIR, subdir))\n",
    "\n",
    "    result.to_csv(os.path.join(SAVE_DIR, subdir, \"result.csv\")) # save the result df\n",
    "    report_df.to_csv(os.path.join(SAVE_DIR, subdir, \"report.csv\")) # save the report\n",
    "\n",
    "    with open(os.path.join(SAVE_DIR, subdir, \"args.json\"), \"w\") as f: # save the args\n",
    "        json.dump(args_dict, f, indent=4)\n",
    "\n",
    "result = pd.concat(result) # concat the result list into a df\n",
    "report_df = _make_report(result) # make the report df\n",
    "\n",
    "_save(result, report_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
