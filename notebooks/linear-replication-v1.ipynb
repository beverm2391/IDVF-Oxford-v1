{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the 65M data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/data/processed-5yr-93-minute/65min.csv\", index_col=0)\n",
    "# assuming 6 65-minute periods per day\n",
    "back_day = 6*20 # 20 days\n",
    "window_length = 6*250 # 250 days\n",
    "train_size = 6*1000 # 1000 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.ffill(inplace=True)\n",
    "data.bfill(inplace=True)\n",
    "assert data.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['datetime'] = pd.to_datetime(data['datetime'], utc=True)\n",
    "data.set_index('datetime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = data.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rv(series: pd.Series, window: int) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Realized volatility is defined in [Volatility Forecasting with Machine Learning\n",
    "    and Intraday Commonality](https://arxiv.org/pdf/2202.08962.pdf) as:\n",
    "\n",
    "    $$RV_{i,t}(h)=\\log(\\sum_{s=t-h+1}^{t}r^2_{i,s})$$\n",
    "    \"\"\"\n",
    "    assert window > 0, \"Window must be greater than 0\"\n",
    "    fuzz = 1e-16\n",
    "    log_returns = np.log(series).diff() # log returns\n",
    "    sum_of_squares = log_returns.rolling(window=window).apply(lambda x: np.sum(x**2), raw=True)\n",
    "    rv = np.log(sum_of_squares + fuzz)\n",
    "    assert rv.isna().sum() == window, \"RV should have NaNs at the beginning\" # ? should have one nan from logret and window - 1 from rolling = window\n",
    "    return rv\n",
    "\n",
    "for ind in namelist:\n",
    "    data[ind + \"_logvol\"] = rv(data[ind], window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to reverse engineer the preprocess code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class preprocess():\n",
    "    def __init__(self, input, target, back_day = list(range(0,15)), forward_day = 1):\n",
    "        # x attribute will hold the predictor variables\n",
    "        # y attribute will hold the target variable\n",
    "        # idx attribute will hold the date\n",
    "\n",
    "        #input is a list of dataframes, for example [price,volatility] with index as the same as target.\n",
    "        self.x = []\n",
    "        for df in input:\n",
    "            # Shift the dataframe by each value in back_day and concatenate along columns\n",
    "            shifted_df = pd.concat(\n",
    "                list(map(lambda n: df.shift(n), back_day)), axis=1\n",
    "            ).reset_index(drop=True).loc[:, ::-1] # Also, reset index and drop to align with the target\n",
    "            self.x.append(np.expand_dims(np.array(shifted_df), axis=2)) # Expand dimensions to make it compatible for future concatenation\n",
    "        \n",
    "        self.x = np.concatenate(tuple(self.x), axis=2) # Concatenate all processed input data along the last axis\n",
    "        self.idx1 = [~np.any(np.isnan(p)) for p in self.x] # Create an index mask where none of the elements in the x dataframes are NaN\n",
    "        self.y = target.shift(-forward_day) # Shift the target by forward_day to align with predictor variables\n",
    "        self.y = pd.DataFrame((self.y)).reset_index(drop=True) # Reset index to align with self.x\n",
    "        self.idx2 = self.y.notna().all(axis=1) # Create an index mask where none of the elements in the y dataframe are NaN\n",
    "        self.idx = np.logical_and(self.idx1, self.idx2) # Combine the two index masks\n",
    "        \n",
    "        # Filter x and y data based on combined index mask\n",
    "        self.x = self.x[self.idx]\n",
    "        self.y = np.array(self.y[self.idx].reset_index(drop=True))\n",
    "\n",
    "        # Filter date based on combined index mask\n",
    "        self.idx = data.index[self.idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, input, target, back_day = list(range(0,15)), forward_day = 1):\n",
    "        # this liss(range(0,15)), forward_day = 1 seem to correspond to the lookback window and the forecast horizon\n",
    "        # ! input is a list of dataframes, for example [price,volatility] with index as the same as target.\n",
    "        # list of dfs holds all the results, target is the actual \"input\" column\n",
    "        \n",
    "        # ! Section 1 - make incrementally shifted seqences for each df in the input list\n",
    "        self.x = []\n",
    "        for df in input:\n",
    "            # Shift the dataframe by each value in back_day and concatenate along columns\n",
    "            # ! detailed explanation below\n",
    "            shifted_df = pd.concat(\n",
    "                list(map(lambda n: df.shift(n), back_day)), axis=1\n",
    "            ).reset_index(drop=True).loc[:, ::-1]\n",
    "            self.x.append(np.expand_dims(np.array(shifted_df), axis=2)) # Expand dimensions to make it compatible for future concatenation\n",
    "\n",
    "        self.x = np.concatenate(tuple(self.x), axis=2) # Concatenate all processed input data along the last axis\n",
    "\n",
    "        # ! X shape = (7516, 15, 1), rows / columns / channels\n",
    "        # ! X shape = (number of agg bars) / (back day list len) / (#dfs in input list)\n",
    "\n",
    "        self.x = np.concatenate(tuple(self.x), axis=2) # Concatenate all processed input data along the last axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "shifted_df = pd.concat(\n",
    "    list(map(lambda n: df.shift(n), back_day)), axis=1\n",
    ").reset_index(drop=True).loc[:, ::-1]\n",
    "```\n",
    "\n",
    "Okay, so. df:\n",
    "\n",
    "```\n",
    "   value\n",
    "0      1\n",
    "1      2\n",
    "2      3\n",
    "```\n",
    "\n",
    "gets mapped and shifted to the back_day list (list(range(0, 15)))\n",
    "\n",
    "example with list [0, 1]\n",
    "\n",
    "```\n",
    "   value       value\n",
    "0      1           NaN\n",
    "1      2           1\n",
    "2      3           2\n",
    "```\n",
    "\n",
    "Then they all get concatenated into one df. Index is dropped and the columns are reversed (putting the lagging columns first)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dfs = [data[name+\"_logvol\"] for name in namelist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in test_dfs:\n",
    "    shifted = pd.concat(\n",
    "        list(map(lambda n: df.shift(n), list(range(0,15)))), axis=1\n",
    "    ).reset_index(drop=True).loc[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>TMO_logvol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.746800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.746800</td>\n",
       "      <td>-2.749263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.746800</td>\n",
       "      <td>-2.749263</td>\n",
       "      <td>-2.750394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.746800</td>\n",
       "      <td>-2.749263</td>\n",
       "      <td>-2.750394</td>\n",
       "      <td>-2.752106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.746800</td>\n",
       "      <td>-2.749263</td>\n",
       "      <td>-2.750394</td>\n",
       "      <td>-2.752106</td>\n",
       "      <td>-2.753366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7511</th>\n",
       "      <td>-2.610986</td>\n",
       "      <td>-2.610055</td>\n",
       "      <td>-2.609934</td>\n",
       "      <td>-2.609838</td>\n",
       "      <td>-2.609731</td>\n",
       "      <td>-2.610711</td>\n",
       "      <td>-2.611303</td>\n",
       "      <td>-2.611142</td>\n",
       "      <td>-2.611172</td>\n",
       "      <td>-2.612094</td>\n",
       "      <td>-2.612153</td>\n",
       "      <td>-2.616261</td>\n",
       "      <td>-2.615733</td>\n",
       "      <td>-2.613411</td>\n",
       "      <td>-2.613493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7512</th>\n",
       "      <td>-2.610055</td>\n",
       "      <td>-2.609934</td>\n",
       "      <td>-2.609838</td>\n",
       "      <td>-2.609731</td>\n",
       "      <td>-2.610711</td>\n",
       "      <td>-2.611303</td>\n",
       "      <td>-2.611142</td>\n",
       "      <td>-2.611172</td>\n",
       "      <td>-2.612094</td>\n",
       "      <td>-2.612153</td>\n",
       "      <td>-2.616261</td>\n",
       "      <td>-2.615733</td>\n",
       "      <td>-2.613411</td>\n",
       "      <td>-2.613493</td>\n",
       "      <td>-2.614106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7513</th>\n",
       "      <td>-2.609934</td>\n",
       "      <td>-2.609838</td>\n",
       "      <td>-2.609731</td>\n",
       "      <td>-2.610711</td>\n",
       "      <td>-2.611303</td>\n",
       "      <td>-2.611142</td>\n",
       "      <td>-2.611172</td>\n",
       "      <td>-2.612094</td>\n",
       "      <td>-2.612153</td>\n",
       "      <td>-2.616261</td>\n",
       "      <td>-2.615733</td>\n",
       "      <td>-2.613411</td>\n",
       "      <td>-2.613493</td>\n",
       "      <td>-2.614106</td>\n",
       "      <td>-2.613911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7514</th>\n",
       "      <td>-2.609838</td>\n",
       "      <td>-2.609731</td>\n",
       "      <td>-2.610711</td>\n",
       "      <td>-2.611303</td>\n",
       "      <td>-2.611142</td>\n",
       "      <td>-2.611172</td>\n",
       "      <td>-2.612094</td>\n",
       "      <td>-2.612153</td>\n",
       "      <td>-2.616261</td>\n",
       "      <td>-2.615733</td>\n",
       "      <td>-2.613411</td>\n",
       "      <td>-2.613493</td>\n",
       "      <td>-2.614106</td>\n",
       "      <td>-2.613911</td>\n",
       "      <td>-2.618732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7515</th>\n",
       "      <td>-2.609731</td>\n",
       "      <td>-2.610711</td>\n",
       "      <td>-2.611303</td>\n",
       "      <td>-2.611142</td>\n",
       "      <td>-2.611172</td>\n",
       "      <td>-2.612094</td>\n",
       "      <td>-2.612153</td>\n",
       "      <td>-2.616261</td>\n",
       "      <td>-2.615733</td>\n",
       "      <td>-2.613411</td>\n",
       "      <td>-2.613493</td>\n",
       "      <td>-2.614106</td>\n",
       "      <td>-2.613911</td>\n",
       "      <td>-2.618732</td>\n",
       "      <td>-2.618722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6016 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TMO_logvol  TMO_logvol  TMO_logvol  TMO_logvol  TMO_logvol  TMO_logvol  \\\n",
       "1500         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1501         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1502         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1503         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1504         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "7511   -2.610986   -2.610055   -2.609934   -2.609838   -2.609731   -2.610711   \n",
       "7512   -2.610055   -2.609934   -2.609838   -2.609731   -2.610711   -2.611303   \n",
       "7513   -2.609934   -2.609838   -2.609731   -2.610711   -2.611303   -2.611142   \n",
       "7514   -2.609838   -2.609731   -2.610711   -2.611303   -2.611142   -2.611172   \n",
       "7515   -2.609731   -2.610711   -2.611303   -2.611142   -2.611172   -2.612094   \n",
       "\n",
       "      TMO_logvol  TMO_logvol  TMO_logvol  TMO_logvol  TMO_logvol  TMO_logvol  \\\n",
       "1500         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1501         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1502         NaN         NaN         NaN         NaN         NaN         NaN   \n",
       "1503         NaN         NaN         NaN         NaN         NaN   -2.746800   \n",
       "1504         NaN         NaN         NaN         NaN   -2.746800   -2.749263   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "7511   -2.611303   -2.611142   -2.611172   -2.612094   -2.612153   -2.616261   \n",
       "7512   -2.611142   -2.611172   -2.612094   -2.612153   -2.616261   -2.615733   \n",
       "7513   -2.611172   -2.612094   -2.612153   -2.616261   -2.615733   -2.613411   \n",
       "7514   -2.612094   -2.612153   -2.616261   -2.615733   -2.613411   -2.613493   \n",
       "7515   -2.612153   -2.616261   -2.615733   -2.613411   -2.613493   -2.614106   \n",
       "\n",
       "      TMO_logvol  TMO_logvol  TMO_logvol  \n",
       "1500         NaN         NaN   -2.746800  \n",
       "1501         NaN   -2.746800   -2.749263  \n",
       "1502   -2.746800   -2.749263   -2.750394  \n",
       "1503   -2.749263   -2.750394   -2.752106  \n",
       "1504   -2.750394   -2.752106   -2.753366  \n",
       "...          ...         ...         ...  \n",
       "7511   -2.615733   -2.613411   -2.613493  \n",
       "7512   -2.613411   -2.613493   -2.614106  \n",
       "7513   -2.613493   -2.614106   -2.613911  \n",
       "7514   -2.614106   -2.613911   -2.618732  \n",
       "7515   -2.613911   -2.618732   -2.618722  \n",
       "\n",
       "[6016 rows x 15 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted[6*250:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7516, 15, 1)\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "# print(np.array(shifted)) # get matrix\n",
    "# print(np.expand_dims(np.array(shifted), axis=2)) # add dimension\n",
    "new = np.expand_dims(np.array(shifted), axis=2)\n",
    "print(new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[0][1][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
