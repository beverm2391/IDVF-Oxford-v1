{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from typing import Dict\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_preprocess(data, windsorize=True):\n",
    "    data = data.ffill()\n",
    "    data = data.bfill()\n",
    "    assert data.isna().sum().sum() == 0\n",
    "\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], utc=True).dt.tz_convert('US/Eastern')\n",
    "    data.set_index('datetime', inplace=True)\n",
    "\n",
    "    data.columns = [col for col in data.columns if col != 'datetime'] # filter out datetime\n",
    "    date = data.index\n",
    "\n",
    "    namelist = data.columns.tolist()\n",
    "\n",
    "    if windsorize:\n",
    "        for clm in data.columns:\n",
    "            max_p = np.percentile(data[clm], 99.9)\n",
    "            min_p = np.percentile(data[clm], 0.1)\n",
    "\n",
    "            data.loc[data[clm] > max_p, clm] = max_p\n",
    "            data.loc[data[clm] < min_p, clm] = min_p\n",
    "\n",
    "    return data, date, namelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_data = pd.read_csv('/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/data/processed-5yr-93-minute/65min_rv.csv', index_col=0)\n",
    "ret_data = pd.read_csv('/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/data/processed-5yr-93-minute/65min_log_ret.csv', index_col=0)\n",
    "\n",
    "back_day = 6*20\n",
    "back_day = list(range(back_day))\n",
    "window_length = 6*60\n",
    "train_size = 1000 #! MODIFIED for smaller dataset\n",
    "\n",
    "rv_ppd, date, namelist = initial_preprocess(rv_data) # preprocess data\n",
    "ret_ppd, date2, namelist2 = initial_preprocess(ret_data) # preprocess data\n",
    "\n",
    "assert (date == date2).all() # check that dates are the same\n",
    "assert namelist == namelist2 # check that names are the same\n",
    "\n",
    "rv_ppd.columns = [col + '_logvol' for col in rv_ppd.columns] # rename columns\n",
    "ret_ppd.columns = [col + '_ret' for col in ret_ppd.columns] # rename columns\n",
    "\n",
    "data = pd.concat([rv_ppd, ret_ppd], axis=1) # combine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ! No change from linear script \n",
    "class preprocess():\n",
    "    def __init__(self, input, target, back_day = list(range(0,15)), forward_day = 1):\n",
    "        #input is a list of dataframes, for example [price,volatility] with index as the same as target.\n",
    "        self.x = []\n",
    "        for _ in input:\n",
    "            self.x.append(np.expand_dims(np.array(pd.concat(list(map(lambda n: _.shift(n), back_day)), axis=1).reset_index(drop=True).loc[:,::-1]),axis =2))\n",
    "        self.x = np.concatenate(tuple(self.x),axis =2)\n",
    "        self.idx1 = [~np.any(np.isnan(p)) for p in self.x]\n",
    "        self.y = target.shift(-forward_day)\n",
    "        self.y = pd.DataFrame((self.y)).reset_index(drop=True)\n",
    "        self.idx2 = self.y.notna().all(axis = 1)\n",
    "        self.idx = np.logical_and(self.idx1, self.idx2)\n",
    "        self.x = self.x[self.idx]\n",
    "        self.y = np.array(self.y[self.idx].reset_index(drop = True))\n",
    "\n",
    "        self.idx = data.index[self.idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rolling_predict():\n",
    "    def __init__(self, keywords = ['XVZ_volatility'], back_day = list(range(0,15)), lr = 0.001):\n",
    "        self.back_day = back_day\n",
    "        self.lr = lr\n",
    "        self.keywords = keywords\n",
    "        temp = [data[namelist[0]+'_logvol'],data[namelist[0]+'_ret']] # ! This is new, using ret\n",
    "        self.a = preprocess(temp,data[namelist[0]+'_logvol'], back_day = back_day)\n",
    "\n",
    "        for ind in namelist[1:]:\n",
    "            temp = []\n",
    "            for i in [ ind+'_logvol',ind+'_ret']: # ! This is new, using ret\n",
    "\n",
    "                temp.append(data[i])\n",
    "            temp_a = preprocess(temp,data[ind+'_logvol'], back_day = back_day)\n",
    "            self.a.x = np.concatenate([self.a.x, temp_a.x],axis = 0 )\n",
    "            self.a.y = np.concatenate([self.a.y, temp_a.y],axis = 0 )\n",
    "            self.a.idx = np.concatenate([self.a.idx, temp_a.idx],axis = 0 )\n",
    "\n",
    "    def train(self, train_index, predict_index,  lr,  names, Epoch_num = 300, pre = True):\n",
    "\n",
    "        clf = linear_model.Lasso(alpha=1e-4,tol=1e-3) # ! new model\n",
    "\n",
    "        temp_train_start = np.where(self.a.idx == train_index[0])\n",
    "        temp_index_train = []\n",
    "        for i in temp_train_start[0]:\n",
    "            temp_index_train.extend(list(range(i,i+len(train_index))))\n",
    "        temp_predict_start = np.where(self.a.idx == predict_index[0])\n",
    "        temp_index_predict= []\n",
    "        for i in temp_predict_start[0]:\n",
    "            temp_index_predict.extend(list(range(i,i+len(predict_index))))\n",
    "        train_x = self.a.x[temp_index_train]\n",
    "        train_y = self.a.y[temp_index_train]\n",
    "        test_x = self.a.x[temp_index_predict]\n",
    "        test_y = self.a.y[temp_index_predict]\n",
    "\n",
    "        # ! new stuff\n",
    "        train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "        test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "\n",
    "        clf.fit(train_x,train_y)\n",
    "\n",
    "        predict = clf.predict(test_x)\n",
    "\n",
    "        # plot_valid_exp = np.exp(plot_valid[['out','real']])\n",
    "        # print(np.mean((plot_valid_exp.iloc[:,0]-plot_valid_exp.iloc[:,1])**2))\n",
    "        # plt.plot(train_list)\n",
    "        # plt.plot(valid_list)\n",
    "        predict = np.reshape(predict, (-1, len(namelist)), 'F')\n",
    "        test_y = np.reshape(test_y, (-1, len(namelist)), 'F')\n",
    "        plot_valid = np.concatenate((predict, test_y), axis=1)\n",
    "        plot_valid = pd.DataFrame(plot_valid)\n",
    "        plot_valid.index = date[(np.where(date == predict_index[0])[0][0] + 1):(\n",
    "                    np.where(date == predict_index[-1])[0][0] + 2)]\n",
    "        plot_valid.columns = [x + 'out' for x in namelist] + [x + 'real' for x in namelist]\n",
    "        return plot_valid\n",
    "    \n",
    "    def run(self, window_length, train_size, Epoch_num = 2, pre = True):\n",
    "        T = int(self.a.x.shape[0]/len(namelist))\n",
    "        result_list = []\n",
    "\n",
    "        # ! MODIFIED CODE =========================================================\n",
    "        test_start_date = '2020-06-30' # this is the last date of train, so test will start on the next day\n",
    "        test_start_date = pd.Timestamp(f'{test_start_date} 10:35', tz='US/Eastern') #! this dataset uses intervals form 10:35-16:00 so this should be 10:35 not 9:30\n",
    "        start_index = np.where(self.a.idx == test_start_date)[0][0]\n",
    "        # ! END MODIFIED CODE =====================================================\n",
    "\n",
    "        for start in range(start_index,T-1, window_length):\n",
    "            print(self.a.idx[start])\n",
    "            if start + window_length <= T - 1:\n",
    "                result_list.append(\n",
    "                    self.train(Epoch_num=Epoch_num, train_index=self.a.idx[start_index - train_size:start],\n",
    "                                predict_index=self.a.idx[start:start + window_length], lr=None, names=None, pre=pre))\n",
    "            else:\n",
    "                result_list.append(\n",
    "                    self.train(Epoch_num=Epoch_num, train_index=self.a.idx[start_index - train_size:start],\n",
    "                                predict_index=self.a.idx[start: T - 1], lr=None, names=None, pre=pre))\n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30 10:35:00-04:00\n",
      "2020-09-24 10:35:00-04:00\n",
      "2020-12-18 12:45:00-05:00\n",
      "2021-03-18 14:55:00-04:00\n",
      "2021-06-14 14:55:00-04:00\n",
      "2021-09-08 14:55:00-04:00\n",
      "2021-12-03 10:35:00-05:00\n",
      "2022-03-02 10:35:00-05:00\n",
      "2022-05-26 10:35:00-04:00\n",
      "2022-08-23 10:35:00-04:00\n",
      "2022-11-16 10:35:00-05:00\n",
      "2023-02-14 12:45:00-05:00\n",
      "2023-05-11 12:45:00-04:00\n",
      "2023-08-08 14:55:00-04:00\n"
     ]
    }
   ],
   "source": [
    "q = rolling_predict( back_day= back_day,\n",
    "            lr=0.001)\n",
    "result = q.run(window_length, train_size, Epoch_num = 2,pre = False)\n",
    "# ! END UNMODIFIED CODE =========================================================\n",
    "\n",
    "# ! REPORTING AND SAVING (modified) ================================================\n",
    "def _make_report(result: pd.DataFrame):\n",
    "        report_df = pd.DataFrame(index = namelist,columns=['MSE','r2_score']) # init report df with MSE and r square\n",
    "        \n",
    "        test_start_date = '2020-06-30' # this is the last date of train, so test will start on the next day\n",
    "        test_start_date = pd.Timestamp(f'{test_start_date} 10:35', tz='US/Eastern') #! this dataset uses intervals form 10:35-16:00 so this should be 10:35 not 9:30\n",
    "        # start the result df freom the test start date\n",
    "        result = result.loc[test_start_date:]\n",
    "\n",
    "        for i in namelist:\n",
    "            # report_df.loc[i,'MSE'] = mean_squared_error(result[i+'out'],result[i+'real']) # calculate MSE\n",
    "            # ! this original code is technically backwards but its sqared so it doesn't matter\n",
    "            report_df.loc[i,'MSE'] = mean_squared_error( result[i + 'real'],result[i + 'out']) # calculate MSE\n",
    "            report_df.loc[i,'r2_score'] = r2_score( result[i + 'real'],result[i + 'out']) # calculate r square\n",
    "            report_df.loc[i,'MAPE'] = mean_absolute_percentage_error( result[i + 'real'],result[i + 'out']) # calculate MAPE\n",
    "        return report_df\n",
    "    \n",
    "def _save(result: pd.DataFrame, report_df: pd.DataFrame, args_dict: Dict = None):\n",
    "    SAVE_DIR = \"/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/outputs/lasso-replication-v1/\"\n",
    "    if not os.path.exists(SAVE_DIR):\n",
    "        os.makedirs(SAVE_DIR)\n",
    "    subdir = f\"{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    os.makedirs(os.path.join(SAVE_DIR, subdir))\n",
    "\n",
    "    result.to_csv(os.path.join(SAVE_DIR, subdir, \"result.csv\")) # save the result df\n",
    "    report_df.to_csv(os.path.join(SAVE_DIR, subdir, \"report.csv\")) # save the report\n",
    "\n",
    "    with open(os.path.join(SAVE_DIR, subdir, \"args.json\"), \"w\") as f: # save the args\n",
    "        json.dump(args_dict, f, indent=4)\n",
    "\n",
    "result = pd.concat(result) # concat the result list into a df\n",
    "report_df = _make_report(result) # make the report df\n",
    "\n",
    "_save(result, report_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSE          0.21289\n",
       "r2_score    0.747073\n",
       "MAPE        0.032429\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
