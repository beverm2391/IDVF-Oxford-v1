{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Union\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from lib.utils import get_93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_preprocess(data: pd.DataFrame, windsorize=True):\n",
    "    \"\"\"\n",
    "    Handle missing values, convert datetime to index, windsorize outliers, rename columns\n",
    "    \"\"\"\n",
    "    data = data.ffill()\n",
    "    data = data.bfill()\n",
    "    assert data.isna().sum().sum() == 0\n",
    "\n",
    "    data['datetime'] = pd.to_datetime(data['datetime'], utc=True).dt.tz_convert('US/Eastern')\n",
    "    data.set_index('datetime', inplace=True)\n",
    "\n",
    "    data.columns = [col for col in data.columns if col != 'datetime'] # filter out datetime\n",
    "    namelist = data.columns.tolist() # save column names (before renaming)\n",
    "    data.columns = [col + '_logvol' for col in data.columns] # rename columns\n",
    "    date = data.index\n",
    "\n",
    "    if windsorize:\n",
    "        for clm in data.columns:\n",
    "            max_p = np.percentile(data[clm], 99.9)\n",
    "            min_p = np.percentile(data[clm], 0.1)\n",
    "\n",
    "            data.loc[data[clm] > max_p, clm] = max_p\n",
    "            data.loc[data[clm] < min_p, clm] = min_p\n",
    "    \n",
    "    return data, date, namelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "back_day = 15\n",
    "back_day = list(range(back_day))\n",
    "window_length = 6*250\n",
    "train_size = 1000 #! MODIFIED for smaller dataset\n",
    "forward_day = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv_data = pd.read_csv('/Users/beneverman/Documents/Coding/QuantHive/IDVF-Oxford-v1/data/processed-5yr-93-minute/65min_rv.csv', index_col=0)\n",
    "rv_data, date, namelist = initial_preprocess(rv_data, windsorize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TMO_logvol</th>\n",
       "      <th>ABT_logvol</th>\n",
       "      <th>HD_logvol</th>\n",
       "      <th>MCD_logvol</th>\n",
       "      <th>PG_logvol</th>\n",
       "      <th>CAT_logvol</th>\n",
       "      <th>DIS_logvol</th>\n",
       "      <th>CCI_logvol</th>\n",
       "      <th>JNJ_logvol</th>\n",
       "      <th>KO_logvol</th>\n",
       "      <th>...</th>\n",
       "      <th>COST_logvol</th>\n",
       "      <th>IBM_logvol</th>\n",
       "      <th>ADP_logvol</th>\n",
       "      <th>AVGO_logvol</th>\n",
       "      <th>WMT_logvol</th>\n",
       "      <th>AMGN_logvol</th>\n",
       "      <th>INTU_logvol</th>\n",
       "      <th>AXP_logvol</th>\n",
       "      <th>MMC_logvol</th>\n",
       "      <th>CB_logvol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-11 10:35:00-04:00</th>\n",
       "      <td>-9.302132</td>\n",
       "      <td>-9.308770</td>\n",
       "      <td>-8.861162</td>\n",
       "      <td>-9.032787</td>\n",
       "      <td>-9.181782</td>\n",
       "      <td>-8.267610</td>\n",
       "      <td>-8.949561</td>\n",
       "      <td>-9.245858</td>\n",
       "      <td>-9.123982</td>\n",
       "      <td>-9.574766</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.758462</td>\n",
       "      <td>-9.029469</td>\n",
       "      <td>-9.164025</td>\n",
       "      <td>-7.821013</td>\n",
       "      <td>-9.906052</td>\n",
       "      <td>-8.309061</td>\n",
       "      <td>-7.986252</td>\n",
       "      <td>-8.662172</td>\n",
       "      <td>-9.824389</td>\n",
       "      <td>-9.117123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-11 11:40:00-04:00</th>\n",
       "      <td>-9.226515</td>\n",
       "      <td>-9.660382</td>\n",
       "      <td>-9.765163</td>\n",
       "      <td>-10.027525</td>\n",
       "      <td>-10.502906</td>\n",
       "      <td>-8.801236</td>\n",
       "      <td>-10.125150</td>\n",
       "      <td>-10.421172</td>\n",
       "      <td>-10.023504</td>\n",
       "      <td>-10.618561</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.126290</td>\n",
       "      <td>-9.864239</td>\n",
       "      <td>-9.209012</td>\n",
       "      <td>-8.637280</td>\n",
       "      <td>-10.469171</td>\n",
       "      <td>-9.083652</td>\n",
       "      <td>-8.634823</td>\n",
       "      <td>-9.688864</td>\n",
       "      <td>-10.128361</td>\n",
       "      <td>-9.916038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-11 12:45:00-04:00</th>\n",
       "      <td>-9.818327</td>\n",
       "      <td>-10.029960</td>\n",
       "      <td>-10.518059</td>\n",
       "      <td>-10.743978</td>\n",
       "      <td>-10.994644</td>\n",
       "      <td>-9.591604</td>\n",
       "      <td>-10.272350</td>\n",
       "      <td>-10.747697</td>\n",
       "      <td>-10.491507</td>\n",
       "      <td>-11.048911</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.732626</td>\n",
       "      <td>-10.336389</td>\n",
       "      <td>-9.891691</td>\n",
       "      <td>-9.291962</td>\n",
       "      <td>-10.898001</td>\n",
       "      <td>-9.966830</td>\n",
       "      <td>-9.518611</td>\n",
       "      <td>-10.129218</td>\n",
       "      <td>-10.798520</td>\n",
       "      <td>-10.359858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-11 13:50:00-04:00</th>\n",
       "      <td>-10.207846</td>\n",
       "      <td>-10.672297</td>\n",
       "      <td>-10.974280</td>\n",
       "      <td>-11.049742</td>\n",
       "      <td>-11.168651</td>\n",
       "      <td>-9.828537</td>\n",
       "      <td>-10.841925</td>\n",
       "      <td>-11.778167</td>\n",
       "      <td>-10.952831</td>\n",
       "      <td>-11.755173</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.943079</td>\n",
       "      <td>-10.542780</td>\n",
       "      <td>-10.012840</td>\n",
       "      <td>-9.699978</td>\n",
       "      <td>-11.319553</td>\n",
       "      <td>-10.194840</td>\n",
       "      <td>-9.536182</td>\n",
       "      <td>-10.620143</td>\n",
       "      <td>-11.741473</td>\n",
       "      <td>-10.880489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-11 14:55:00-04:00</th>\n",
       "      <td>-8.921766</td>\n",
       "      <td>-8.968561</td>\n",
       "      <td>-8.872568</td>\n",
       "      <td>-9.690731</td>\n",
       "      <td>-9.740425</td>\n",
       "      <td>-8.682480</td>\n",
       "      <td>-9.503440</td>\n",
       "      <td>-10.269008</td>\n",
       "      <td>-9.185082</td>\n",
       "      <td>-10.092992</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.973373</td>\n",
       "      <td>-9.243132</td>\n",
       "      <td>-9.060507</td>\n",
       "      <td>-8.967603</td>\n",
       "      <td>-9.951001</td>\n",
       "      <td>-9.123352</td>\n",
       "      <td>-8.827453</td>\n",
       "      <td>-9.273452</td>\n",
       "      <td>-9.856659</td>\n",
       "      <td>-9.745645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 11:40:00-04:00</th>\n",
       "      <td>-10.733918</td>\n",
       "      <td>-11.561414</td>\n",
       "      <td>-11.459266</td>\n",
       "      <td>-11.630080</td>\n",
       "      <td>-11.549440</td>\n",
       "      <td>-10.420834</td>\n",
       "      <td>-10.661230</td>\n",
       "      <td>-11.052822</td>\n",
       "      <td>-11.640935</td>\n",
       "      <td>-10.917620</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.752899</td>\n",
       "      <td>-11.384324</td>\n",
       "      <td>-11.297519</td>\n",
       "      <td>-10.206596</td>\n",
       "      <td>-11.178907</td>\n",
       "      <td>-10.680779</td>\n",
       "      <td>-10.645832</td>\n",
       "      <td>-10.627294</td>\n",
       "      <td>-11.829896</td>\n",
       "      <td>-11.312079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 12:45:00-04:00</th>\n",
       "      <td>-11.575774</td>\n",
       "      <td>-11.660044</td>\n",
       "      <td>-11.389878</td>\n",
       "      <td>-11.992928</td>\n",
       "      <td>-11.837725</td>\n",
       "      <td>-10.662594</td>\n",
       "      <td>-11.225769</td>\n",
       "      <td>-9.910547</td>\n",
       "      <td>-12.022989</td>\n",
       "      <td>-10.924749</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.925418</td>\n",
       "      <td>-12.035542</td>\n",
       "      <td>-12.237446</td>\n",
       "      <td>-11.091774</td>\n",
       "      <td>-11.439434</td>\n",
       "      <td>-11.202431</td>\n",
       "      <td>-11.457626</td>\n",
       "      <td>-11.228341</td>\n",
       "      <td>-11.642755</td>\n",
       "      <td>-11.378411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 13:50:00-04:00</th>\n",
       "      <td>-11.869460</td>\n",
       "      <td>-11.628670</td>\n",
       "      <td>-11.684992</td>\n",
       "      <td>-11.961455</td>\n",
       "      <td>-11.665920</td>\n",
       "      <td>-10.952734</td>\n",
       "      <td>-11.278099</td>\n",
       "      <td>-10.838116</td>\n",
       "      <td>-12.250040</td>\n",
       "      <td>-11.185100</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.705529</td>\n",
       "      <td>-12.087832</td>\n",
       "      <td>-11.997735</td>\n",
       "      <td>-10.649890</td>\n",
       "      <td>-11.542805</td>\n",
       "      <td>-11.382209</td>\n",
       "      <td>-11.012721</td>\n",
       "      <td>-11.832090</td>\n",
       "      <td>-11.737761</td>\n",
       "      <td>-11.501302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 14:55:00-04:00</th>\n",
       "      <td>-11.277812</td>\n",
       "      <td>-11.982515</td>\n",
       "      <td>-11.641741</td>\n",
       "      <td>-12.104332</td>\n",
       "      <td>-12.100556</td>\n",
       "      <td>-11.159378</td>\n",
       "      <td>-11.756749</td>\n",
       "      <td>-11.311528</td>\n",
       "      <td>-12.244460</td>\n",
       "      <td>-11.504707</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.609444</td>\n",
       "      <td>-12.312214</td>\n",
       "      <td>-12.193028</td>\n",
       "      <td>-10.515182</td>\n",
       "      <td>-11.398901</td>\n",
       "      <td>-11.671222</td>\n",
       "      <td>-11.120266</td>\n",
       "      <td>-11.961500</td>\n",
       "      <td>-12.197529</td>\n",
       "      <td>-11.755987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-09 16:00:00-04:00</th>\n",
       "      <td>-11.655459</td>\n",
       "      <td>-11.975486</td>\n",
       "      <td>-11.603576</td>\n",
       "      <td>-11.875128</td>\n",
       "      <td>-12.236133</td>\n",
       "      <td>-11.042433</td>\n",
       "      <td>-11.301144</td>\n",
       "      <td>-10.657317</td>\n",
       "      <td>-12.174962</td>\n",
       "      <td>-11.544714</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.556200</td>\n",
       "      <td>-12.348149</td>\n",
       "      <td>-11.806256</td>\n",
       "      <td>-10.442070</td>\n",
       "      <td>-11.731128</td>\n",
       "      <td>-12.157248</td>\n",
       "      <td>-11.144227</td>\n",
       "      <td>-11.330272</td>\n",
       "      <td>-12.216797</td>\n",
       "      <td>-11.786497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7516 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           TMO_logvol  ABT_logvol  HD_logvol  MCD_logvol  \\\n",
       "datetime                                                                   \n",
       "2018-10-11 10:35:00-04:00   -9.302132   -9.308770  -8.861162   -9.032787   \n",
       "2018-10-11 11:40:00-04:00   -9.226515   -9.660382  -9.765163  -10.027525   \n",
       "2018-10-11 12:45:00-04:00   -9.818327  -10.029960 -10.518059  -10.743978   \n",
       "2018-10-11 13:50:00-04:00  -10.207846  -10.672297 -10.974280  -11.049742   \n",
       "2018-10-11 14:55:00-04:00   -8.921766   -8.968561  -8.872568   -9.690731   \n",
       "...                               ...         ...        ...         ...   \n",
       "2023-10-09 11:40:00-04:00  -10.733918  -11.561414 -11.459266  -11.630080   \n",
       "2023-10-09 12:45:00-04:00  -11.575774  -11.660044 -11.389878  -11.992928   \n",
       "2023-10-09 13:50:00-04:00  -11.869460  -11.628670 -11.684992  -11.961455   \n",
       "2023-10-09 14:55:00-04:00  -11.277812  -11.982515 -11.641741  -12.104332   \n",
       "2023-10-09 16:00:00-04:00  -11.655459  -11.975486 -11.603576  -11.875128   \n",
       "\n",
       "                           PG_logvol  CAT_logvol  DIS_logvol  CCI_logvol  \\\n",
       "datetime                                                                   \n",
       "2018-10-11 10:35:00-04:00  -9.181782   -8.267610   -8.949561   -9.245858   \n",
       "2018-10-11 11:40:00-04:00 -10.502906   -8.801236  -10.125150  -10.421172   \n",
       "2018-10-11 12:45:00-04:00 -10.994644   -9.591604  -10.272350  -10.747697   \n",
       "2018-10-11 13:50:00-04:00 -11.168651   -9.828537  -10.841925  -11.778167   \n",
       "2018-10-11 14:55:00-04:00  -9.740425   -8.682480   -9.503440  -10.269008   \n",
       "...                              ...         ...         ...         ...   \n",
       "2023-10-09 11:40:00-04:00 -11.549440  -10.420834  -10.661230  -11.052822   \n",
       "2023-10-09 12:45:00-04:00 -11.837725  -10.662594  -11.225769   -9.910547   \n",
       "2023-10-09 13:50:00-04:00 -11.665920  -10.952734  -11.278099  -10.838116   \n",
       "2023-10-09 14:55:00-04:00 -12.100556  -11.159378  -11.756749  -11.311528   \n",
       "2023-10-09 16:00:00-04:00 -12.236133  -11.042433  -11.301144  -10.657317   \n",
       "\n",
       "                           JNJ_logvol  KO_logvol  ...  COST_logvol  \\\n",
       "datetime                                          ...                \n",
       "2018-10-11 10:35:00-04:00   -9.123982  -9.574766  ...    -9.758462   \n",
       "2018-10-11 11:40:00-04:00  -10.023504 -10.618561  ...   -10.126290   \n",
       "2018-10-11 12:45:00-04:00  -10.491507 -11.048911  ...   -10.732626   \n",
       "2018-10-11 13:50:00-04:00  -10.952831 -11.755173  ...   -10.943079   \n",
       "2018-10-11 14:55:00-04:00   -9.185082 -10.092992  ...    -9.973373   \n",
       "...                               ...        ...  ...          ...   \n",
       "2023-10-09 11:40:00-04:00  -11.640935 -10.917620  ...   -10.752899   \n",
       "2023-10-09 12:45:00-04:00  -12.022989 -10.924749  ...   -10.925418   \n",
       "2023-10-09 13:50:00-04:00  -12.250040 -11.185100  ...   -11.705529   \n",
       "2023-10-09 14:55:00-04:00  -12.244460 -11.504707  ...   -11.609444   \n",
       "2023-10-09 16:00:00-04:00  -12.174962 -11.544714  ...   -11.556200   \n",
       "\n",
       "                           IBM_logvol  ADP_logvol  AVGO_logvol  WMT_logvol  \\\n",
       "datetime                                                                     \n",
       "2018-10-11 10:35:00-04:00   -9.029469   -9.164025    -7.821013   -9.906052   \n",
       "2018-10-11 11:40:00-04:00   -9.864239   -9.209012    -8.637280  -10.469171   \n",
       "2018-10-11 12:45:00-04:00  -10.336389   -9.891691    -9.291962  -10.898001   \n",
       "2018-10-11 13:50:00-04:00  -10.542780  -10.012840    -9.699978  -11.319553   \n",
       "2018-10-11 14:55:00-04:00   -9.243132   -9.060507    -8.967603   -9.951001   \n",
       "...                               ...         ...          ...         ...   \n",
       "2023-10-09 11:40:00-04:00  -11.384324  -11.297519   -10.206596  -11.178907   \n",
       "2023-10-09 12:45:00-04:00  -12.035542  -12.237446   -11.091774  -11.439434   \n",
       "2023-10-09 13:50:00-04:00  -12.087832  -11.997735   -10.649890  -11.542805   \n",
       "2023-10-09 14:55:00-04:00  -12.312214  -12.193028   -10.515182  -11.398901   \n",
       "2023-10-09 16:00:00-04:00  -12.348149  -11.806256   -10.442070  -11.731128   \n",
       "\n",
       "                           AMGN_logvol  INTU_logvol  AXP_logvol  MMC_logvol  \\\n",
       "datetime                                                                      \n",
       "2018-10-11 10:35:00-04:00    -8.309061    -7.986252   -8.662172   -9.824389   \n",
       "2018-10-11 11:40:00-04:00    -9.083652    -8.634823   -9.688864  -10.128361   \n",
       "2018-10-11 12:45:00-04:00    -9.966830    -9.518611  -10.129218  -10.798520   \n",
       "2018-10-11 13:50:00-04:00   -10.194840    -9.536182  -10.620143  -11.741473   \n",
       "2018-10-11 14:55:00-04:00    -9.123352    -8.827453   -9.273452   -9.856659   \n",
       "...                                ...          ...         ...         ...   \n",
       "2023-10-09 11:40:00-04:00   -10.680779   -10.645832  -10.627294  -11.829896   \n",
       "2023-10-09 12:45:00-04:00   -11.202431   -11.457626  -11.228341  -11.642755   \n",
       "2023-10-09 13:50:00-04:00   -11.382209   -11.012721  -11.832090  -11.737761   \n",
       "2023-10-09 14:55:00-04:00   -11.671222   -11.120266  -11.961500  -12.197529   \n",
       "2023-10-09 16:00:00-04:00   -12.157248   -11.144227  -11.330272  -12.216797   \n",
       "\n",
       "                           CB_logvol  \n",
       "datetime                              \n",
       "2018-10-11 10:35:00-04:00  -9.117123  \n",
       "2018-10-11 11:40:00-04:00  -9.916038  \n",
       "2018-10-11 12:45:00-04:00 -10.359858  \n",
       "2018-10-11 13:50:00-04:00 -10.880489  \n",
       "2018-10-11 14:55:00-04:00  -9.745645  \n",
       "...                              ...  \n",
       "2023-10-09 11:40:00-04:00 -11.312079  \n",
       "2023-10-09 12:45:00-04:00 -11.378411  \n",
       "2023-10-09 13:50:00-04:00 -11.501302  \n",
       "2023-10-09 14:55:00-04:00 -11.755987  \n",
       "2023-10-09 16:00:00-04:00 -11.786497  \n",
       "\n",
       "[7516 rows x 93 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocess:\n",
    "    def __init__(self, input_dfs: List[pd.DataFrame], target, back_day: List, forward_day: int):\n",
    "        self.input_dfs = input_dfs\n",
    "        self.target = target\n",
    "        self.back_day = back_day\n",
    "        self.forward_day = forward_day\n",
    "\n",
    "        self.obs_unprocessed = self.input_dfs[0].shape[0] # get the number of observations\n",
    "        self.eop = self.obs_unprocessed - len(self.back_day) - (forward_day-1) # calculate the expected number of observations after preprocessing \n",
    "        \n",
    "        self._generate_shifted_sequences()\n",
    "        self._generate_target_mask_and_date()\n",
    "\n",
    "    def _generate_shifted_sequences(self):\n",
    "        self.x = []\n",
    "        for df in self.input_dfs: # for each input df\n",
    "            shifted_df = pd.concat(\n",
    "                [df.shift(n) for n in self.back_day], axis=1 # shift and concatenate\n",
    "            ).reset_index(drop=True).iloc[:, ::-1] # reset index and reverse order\n",
    "\n",
    "            self.x.append(np.expand_dims(np.array(shifted_df), axis=2)) # expand dims and append on the new dim\n",
    "\n",
    "        self.x = np.concatenate(tuple(self.x), axis=2) # concatenate on the new dim (now we have a single 3d array)\n",
    "        # Sanity check - shape should not change until we apply the mask later\n",
    "        # (num observations, num back days, num features) (7516, 15, 1)\n",
    "        assert self.x.shape == (self.input_dfs[0].shape[0], len(self.back_day), len(self.input_dfs)),\\\n",
    "            f\"Input shape is incorrect, expected {(self.input_dfs[0].shape[0], len(self.back_day), len(self.input_dfs))} but got {self.x.shape}\"\n",
    "\n",
    "    def _generate_target_mask_and_date(self):\n",
    "        non_na_mask = [~np.any(np.isnan(p)) for p in self.x] # make a mask for non-nan values over all features\n",
    "        \n",
    "        # print(f\"Target type: {type(self.target)}\") #? Debug\n",
    "        if type(self.target) == pd.Series: # if the target is a series\n",
    "            self.target = pd.DataFrame(self.target) # convert to df to avoid error in line below where we call .all() and axis=1\n",
    "        \n",
    "        self.y = self.target.shift(-self.forward_day).reset_index(drop=True) # shift target\n",
    "        valid_target_mask = self.y.notna().all(axis=1) # make a mask for valid target values\n",
    "        \n",
    "        self.final_mask = np.logical_and(non_na_mask, valid_target_mask) # combine masks\n",
    "        \n",
    "        self.x = self.x[self.final_mask] # apply mask\n",
    "        self.y = np.array(self.y[self.final_mask].reset_index(drop=True)) # apply mask\n",
    "        self.idx = self.target.index[self.final_mask] # get all dates\n",
    "\n",
    "        # Sanity check - shape should be reduced by the number of back days\n",
    "        # (num observations, num features) (7502, 1)\n",
    "        assert self.x.shape == (self.eop, len(self.back_day), len(self.input_dfs)),\\\n",
    "            f\"Input shape is incorrect, should be {self.eop} x {len(self.back_day)}, {len(self.input_dfs)}, is {self.x.shape}\"\n",
    "\n",
    "class Model(ABC):\n",
    "    @abstractmethod\n",
    "    def train(self, x, y):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, x):\n",
    "        pass\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.coefficients = None\n",
    "        self.fit_intercept = fit_intercept  # Added\n",
    "\n",
    "    def train(self, X, y):\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(\"Mismatched dimensions: X has {} rows but y has {} rows\".format(X.shape[0], y.shape[0]))\n",
    "\n",
    "        if self.fit_intercept:\n",
    "            X = self._add_bias_term(X)  # Added\n",
    "\n",
    "        self.coefficients = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "    def predict(self, X):\n",
    "        if self.coefficients is None:\n",
    "            raise ValueError(\"Model has not been trained yet.\")\n",
    "\n",
    "        if self.fit_intercept: \n",
    "            X = self._add_bias_term(X)  # Added\n",
    "\n",
    "        return X @ self.coefficients\n",
    "\n",
    "    def _add_bias_term(self, X):  # Added\n",
    "        return np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)  # Added\n",
    "\n",
    "class RollingPredict:\n",
    "    def __init__(self, back_day: List, data: pd.DataFrame, namelist: List, window_length: int, forward_day: int = 1):\n",
    "        self.back_day = back_day\n",
    "        self.data = data # store data in attribute\n",
    "        self.namelist = namelist # store namelist in attribute\n",
    "        self.window_length = window_length\n",
    "        self.forward_day = forward_day\n",
    "\n",
    "        # ! Some assertions to make sure everything is good\n",
    "        self.obs_unprocessed = self.data.shape[0] \n",
    "        self.expected_obs_processed = self.obs_unprocessed - len(self.back_day) - (forward_day-1)\n",
    "        # 7516 - 14 - + 1\n",
    "\n",
    "        self._rolling_preprocess() # preprocess all the data fort his window\n",
    "\n",
    "        # some statment to figure out how many models should be trained (based on the window length)\n",
    "        # would be total number of data points \n",
    "\n",
    "        eop = self.expected_obs_processed * len(self.namelist) # expected observations per ticker\n",
    "        x_len = self.preprocess_obj.x.shape[0]\n",
    "        y_len = self.preprocess_obj.y.shape[0]\n",
    "        idx_len = self.preprocess_obj.idx.shape[0]\n",
    "\n",
    "        assert x_len == eop, f\"X shape is incorrect: expected {eop} but got {x_len}\"\n",
    "        assert y_len == eop, f\"Y shape is incorrect: expected {eop} but got {y_len}\"\n",
    "        assert idx_len == eop, f\"IDX shape is incorrect expected {eop} but got {idx_len}\"\n",
    "\n",
    "    def _rolling_preprocess(self):\n",
    "        initial_df = [self.data[self.namelist[0]+'_logvol']] # get the first df\n",
    "        \n",
    "        self.preprocess_obj = Preprocess(initial_df, self.data[self.namelist[0]+'_logvol'], self.back_day, self.forward_day)\n",
    "\n",
    "        assert self.preprocess_obj.x.shape[0] == self.expected_obs_processed, \"Initial preprocess failed - debug in the preprocess class\"\n",
    "\n",
    "        for ticker in self.namelist[1:]:\n",
    "            temp_df = [self.data[ticker + '_logvol']]\n",
    "            temp_preprocess_obj = Preprocess(temp_df, self.data[ticker + '_logvol'], self.back_day, self.forward_day)\n",
    "\n",
    "            self._concatenate_preprocessed_data(temp_preprocess_obj)\n",
    "\n",
    "    def _concatenate_preprocessed_data(self, temp_preprocess_obj):\n",
    "        self.preprocess_obj.x = np.concatenate([self.preprocess_obj.x, temp_preprocess_obj.x], axis=0)\n",
    "        self.preprocess_obj.y = np.concatenate([self.preprocess_obj.y, temp_preprocess_obj.y], axis=0)\n",
    "        self.preprocess_obj.idx = np.concatenate([self.preprocess_obj.idx, temp_preprocess_obj.idx], axis=0)\n",
    "\n",
    "    def train(self, train_index, predict_index):\n",
    "        # Find the indices that correspond to the starting points of our training window.\n",
    "        temp_train_start = np.where(self.preprocess_obj.idx == train_index[0])[0]\n",
    "        \n",
    "        # Create a list of indices that correspond to all data points in the training window.\n",
    "        # For each starting point found, we create a range that defines our actual training window.\n",
    "        temp_index_train = [i for start in temp_train_start for i in range(start, start + len(train_index))]\n",
    "        \n",
    "        # same for predict\n",
    "        temp_predict_start = np.where(self.preprocess_obj.idx == predict_index[0])[0]\n",
    "        temp_index_predict = [i for start in temp_predict_start for i in range(start, start + len(predict_index))]\n",
    "        \n",
    "        train_x = self.preprocess_obj.x[temp_index_train]\n",
    "        train_y = self.preprocess_obj.y[temp_index_train]\n",
    "        test_x = self.preprocess_obj.x[temp_index_predict]\n",
    "        test_y = self.preprocess_obj.y[temp_index_predict]\n",
    "        \n",
    "        # reshape features\n",
    "        train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "        test_x = test_x.reshape(test_x.shape[0], -1)\n",
    "        \n",
    "        model = LinearRegression()\n",
    "        model.train(train_x, train_y)\n",
    "        \n",
    "        predictions = model.predict(test_x) \n",
    "        \n",
    "        # Reshape data for side-by-side comparison.\n",
    "        predictions = np.reshape(predictions, (-1, len(self.namelist)), 'F')\n",
    "        test_y = np.reshape(test_y, (-1, len(self.namelist)), 'F')\n",
    "\n",
    "        results_df = pd.DataFrame(np.concatenate((predictions, test_y), axis=1))\n",
    "        \n",
    "        # ! CONCISE VERSION\n",
    "        # results_df.index = self.preprocess_obj.idx[\n",
    "        #                    (np.where(self.preprocess_obj.idx == predict_index[0])[0][0] + 1):\n",
    "        #                    (np.where(self.preprocess_obj.idx == predict_index[-1])[0][0] + 2)]\n",
    "        # results_df.columns = [x + '_predicted' for x in self.namelist] + [x + '_actual' for x in self.namelist]\n",
    "\n",
    "        # ! VERSION FOR READABILITY \n",
    "        start_idx_position = np.where(self.preprocess_obj.idx == predict_index[0])[0][0] # find the index of the first predict index\n",
    "        end_idx_position = np.where(self.preprocess_obj.idx == predict_index[-1])[0][0] # find the index of the last predict index\n",
    "\n",
    "        # Adjust the starting and ending positions to match the DataFrame index.\n",
    "        adjusted_start = start_idx_position + 1\n",
    "        adjusted_end = end_idx_position + 2\n",
    "\n",
    "        results_df.index = self.preprocess_obj.idx[adjusted_start:adjusted_end]\n",
    "\n",
    "        predicted_columns = [x + '_predicted' for x in self.namelist]\n",
    "        actual_columns = [x + '_actual' for x in self.namelist]\n",
    "        results_df.columns = predicted_columns + actual_columns\n",
    "\n",
    "        # Step 13: Return the results DataFrame.\n",
    "        return results_df\n",
    "\n",
    "    def run(self, window_length, train_size, Epoch_num=0, lr=None):\n",
    "        # Calculate the total number of observations\n",
    "        T = int(self.preprocess_obj.x.shape[0] / len(self.namelist))\n",
    "        result_list = []\n",
    "\n",
    "        # Set the starting date for the test data\n",
    "        test_start_dt_str = '2020-06-30 10:35'\n",
    "        test_start_dt = pd.Timestamp(test_start_dt_str, tz='US/Eastern')\n",
    "        # TODO - make this a parameter or something\n",
    "\n",
    "        assert test_start_dt in self.preprocess_obj.idx, \"Test start date is not in the index\"\n",
    "        start_index = np.where(self.preprocess_obj.idx == test_start_dt)[0][0] \n",
    "\n",
    "        num_windows = int((T - train_size) / window_length) + 1 # ? make sure this work \n",
    "\n",
    "        for start in range(start_index, T - 1, window_length):\n",
    "            print(self.preprocess_obj.idx[start]) #? Debugging\n",
    "\n",
    "            # Determine the range for training and prediction\n",
    "            train_idx_start = self.preprocess_obj.idx[start_index - train_size:start]\n",
    "            \n",
    "            # min function to handle the edge case for the last window\n",
    "            predict_idx_range = self.preprocess_obj.idx[start:min(start + window_length, T)] # T not T-1 because range is exclusive\n",
    "\n",
    "            kwargs = {\n",
    "                \"train_index\": train_idx_start,\n",
    "                \"predict_index\": predict_idx_range,\n",
    "            }\n",
    "\n",
    "            if Epoch_num != 0: kwargs[\"Epoch_num\"] = Epoch_num # for the NN\n",
    "            if lr != None: kwargs[\"lr\"] = lr # for the NN\n",
    "\n",
    "            result = self.train(**kwargs)\n",
    "            result_list.append(result)\n",
    "        # ! ============================================================\n",
    "\n",
    "        return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30 10:35:00-04:00\n",
      "2021-06-28 14:55:00-04:00\n",
      "2022-06-27 10:35:00-04:00\n",
      "2023-06-26 12:45:00-04:00\n"
     ]
    }
   ],
   "source": [
    "rp_args = [back_day, rv_data, namelist, window_length, forward_day]\n",
    "q = RollingPredict(*rp_args)\n",
    "\n",
    "result = q.run(window_length, train_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
